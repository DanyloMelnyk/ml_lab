{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import json\n",
    "import os\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "with open(\"/content/drive/MyDrive/api_keys.json\") as file:\n",
    "  KEYS = json.load(file)\n",
    "\n",
    "os.environ[\"GITHUB_USER\"] = KEYS['GITHUB_USER']\n",
    "os.environ[\"GITHUB_TOKEN\"] = KEYS['GITHUB_TOKEN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -r cda\n",
    "! git clone --branch lab-1 --filter=blob:none https://$GITHUB_USER:$GITHUB_TOKEN@github.com/DanyloMelnyk/ml_lab.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r /content/ml_lab/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login(key=KEYS[\"WANDB_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -o /content/drive/MyDrive/data/INbreastProcessed.zip -d data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import lightning as L\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import wandb\n",
    "from dataloader import create_dataloader\n",
    "from lightning.pytorch.callbacks import (\n",
    "    EarlyStopping,\n",
    "    LearningRateMonitor,\n",
    "    ModelCheckpoint,\n",
    ")\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport classifier_trainer\n",
    "%aimport models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_col = \"segmented_file_path\"\n",
    "optimizer_adam = True\n",
    "\n",
    "train = create_dataloader(\n",
    "    Path(\"../data/INbreast Release 1.0/train_processed_png_labels.csv\"),\n",
    "    is_train=True,\n",
    "    weighted_train_sampler=True,\n",
    "    batch_size=20,\n",
    "    num_workers=8,\n",
    "    images_path_col=images_col,\n",
    "    # unprocessed_file_path,ma_file_path,normalized_file_path,segmented_file_path\n",
    ")\n",
    "test = create_dataloader(\n",
    "    Path(\"../data/INbreast Release 1.0/test_processed_png_labels.csv\"),\n",
    "    is_train=False,\n",
    "    weighted_train_sampler=False,\n",
    "    batch_size=20,\n",
    "    num_workers=8,\n",
    "    images_path_col=images_col,\n",
    ")\n",
    "\n",
    "batch_shape = next(iter(train))[0].shape\n",
    "batch_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.create_squeezenet_model(False)\n",
    "summary(\n",
    "        model,\n",
    "        input_size=batch_shape,\n",
    "        col_names=(\"output_size\", \"num_params\", \"trainable\"),\n",
    "        row_settings=[\"var_names\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if optimizer_adam:\n",
    "    adam_params = {\n",
    "        \"lr\": 0.01,\n",
    "        \"betas\": (0.9, 0.999),\n",
    "        \"weight_decay\": 0.0,\n",
    "        \"amsgrad\": False,\n",
    "        \"eps\": 1e-08,\n",
    "        # batch_shape 20\n",
    "        # epochs 20\n",
    "    }\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=0.001,\n",
    "        weight_decay=0.0005,\n",
    "        betas=(0.5, 0.999),\n",
    "    )\n",
    "    scheduler = None\n",
    "else:\n",
    "    sgd_params = {\n",
    "        \"lr\": 0.0001,\n",
    "        \"momentum\": 0.9,\n",
    "        \"weight_decay\": 0.0001,\n",
    "        # batch_shape 20\n",
    "        # epochs 20\n",
    "        # lr drop factor 0.5\n",
    "        # lr drop period 5\n",
    "    }\n",
    "    optimizer = torch.optim.SGD(model.parameters(), **sgd_params)\n",
    "    scheduler = StepLR(optimizer, 5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_logger = WandbLogger(project='ml_lab', log_model=\"all\")\n",
    "clf_trainer = classifier_trainer.ClassifierTrainer(\n",
    "    net=model,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    num_classes=3,\n",
    ")\n",
    "\n",
    "lr_monitor = LearningRateMonitor(logging_interval=\"step\")\n",
    "early_stopping = EarlyStopping(monitor=\"roc_auc_avg_val\", patience=15, verbose=True, mode=\"max\")\n",
    "checkpoints = ModelCheckpoint(monitor=\"roc_auc_avg_val\", save_last=True, mode=\"max\")\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=20,\n",
    "    log_every_n_steps=3,\n",
    "    logger=wandb_logger,\n",
    "    callbacks=[lr_monitor, early_stopping, checkpoints],\n",
    ")\n",
    "trainer.fit(model=clf_trainer, train_dataloaders=train, val_dataloaders=test)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
